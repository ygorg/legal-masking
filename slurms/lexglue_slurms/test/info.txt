module purge
module load pytorch-gpu/py3/2.1.1

set -x

MODEL_NAME="../../continued_pretraining/models/bert-base-uncased-jz4-4-4-e10-b16-c512-default-exall/checkpoint-4453"
MODEL_BASE_NAME="bert-baseline-CFT"
CACHE_DIR="./data"
LOWER_CASE='True'
BATCH_SIZE=16
ACCUMULATION_STEPS=1
REPORT_TO='none'

TASKS=(
    'ecthr_a'
    'ecthr_b'
    'unfair_tos'
    'eurlex'
    'ledgar'
    'scotus'
)


SEEDS=(1 2 3)
arr=()
# Itérer sur chaque tâche

for SEED in "${SEEDS[@]}"; do
  for TASK in "${TASKS[@]}"; do
      COMMAND="srun -l python experiments/${TASK}.py \
          --model_name_or_path ${MODEL_NAME} \
          --do_lower_case ${LOWER_CASE} \
          --task ${TASK} \
          --output_dir logs/${TASK}/${MODEL_BASE_NAME}/seed_${SEED} \
          --cache_dir ${CACHE_DIR} \
          --do_train \
          --do_eval \
          --do_pred \
          --report_to ${REPORT_TO} \
          --overwrite_output_dir \
          --load_best_model_at_end \
          --metric_for_best_model micro-f1 \
          --greater_is_better True \
          --evaluation_strategy epoch \
          --save_strategy epoch \
          --save_total_limit 5 \
          --num_train_epochs 20 \
          --learning_rate 3e-5 \
          --per_device_train_batch_size ${BATCH_SIZE} \
          --per_device_eval_batch_size ${BATCH_SIZE} \
          --seed ${SEED} \
          --fp16 \
          --fp16_full_eval \
          --gradient_accumulation_steps ${ACCUMULATION_STEPS} \
          --eval_accumulation_steps ${ACCUMULATION_STEPS}"

      # Ajouter l'argument --hierarchical uniquement pour certaines tâches
      if [[ "$TASK" == "ecthr_a" ]] || [[ "$TASK" == "ecthr_b" ]] || [[ "$TASK" == "scotus" ]]; then
          COMMAND+=" --hierarchical False"
      fi

      COMMAND+=" && python statistics.py"
      arr+=(COMMAND)

      # Exécuter la commande
  done
done


INDEX=${SLURM_ARRAY_TASK_ID}
COMMAND_SRUN=${arr[$INDEX]}
eval "${COMMAND_SRUN}"
